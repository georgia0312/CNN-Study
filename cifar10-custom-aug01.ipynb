{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","metadata":{"execution":{"iopub.status.busy":"2023-01-15T08:28:10.869489Z","iopub.execute_input":"2023-01-15T08:28:10.870633Z","iopub.status.idle":"2023-01-15T08:28:10.897970Z","shell.execute_reply.started":"2023-01-15T08:28:10.870522Z","shell.execute_reply":"2023-01-15T08:28:10.897081Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\n\nimport random as python_random\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.datasets import cifar10\n\ndef set_random_seed(seed_value):\n    np.random.seed(seed_value)\n    python_random.seed(seed_value)\n    tf.random.set_seed(seed_value)\n    \ndef get_preprocessed_data(images, labels, scaling=True):\n    if scaling:\n        images = np.array(images/255.0, dtype=np.float32)\n    else:\n        images = np.array(images, dtype=np.float32)\n        \n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\ndef get_preprocessed_ohe(images, labels):\n    images, labels = get_preprocessed_data(images, labels, scaling=False)\n    oh_labels = to_categorical(labels)\n    return images, oh_labels\n\ndef get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n    \n    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n    \n    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels)\n\n\nset_random_seed(2021)\n(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n\n(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n\nprint(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-01-15T08:28:46.415871Z","iopub.execute_input":"2023-01-15T08:28:46.416230Z","iopub.status.idle":"2023-01-15T08:28:58.878426Z","shell.execute_reply.started":"2023-01-15T08:28:46.416201Z","shell.execute_reply":"2023-01-15T08:28:58.877299Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170500096/170498071 [==============================] - 2s 0us/step\n170508288/170498071 [==============================] - 2s 0us/step\n(42500, 32, 32, 3) (42500, 10) (7500, 32, 32, 3) (7500, 10) (10000, 32, 32, 3) (10000, 10)\n","output_type":"stream"}]},{"cell_type":"code","source":"IMAGE_SIZE = 32\nBATCH_SIZE = 64","metadata":{"execution":{"iopub.status.busy":"2023-01-15T08:29:36.423610Z","iopub.execute_input":"2023-01-15T08:29:36.424267Z","iopub.status.idle":"2023-01-15T08:29:36.429424Z","shell.execute_reply.started":"2023-01-15T08:29:36.424228Z","shell.execute_reply":"2023-01-15T08:29:36.428309Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_generator = ImageDataGenerator(\n     horizontal_flip=True,\n     rescale=1/255.0\n)\n\nvalid_generator = ImageDataGenerator(rescale=1/255.0)\n\nflow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\nflow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T08:32:53.762960Z","iopub.execute_input":"2023-01-15T08:32:53.764060Z","iopub.status.idle":"2023-01-15T08:32:53.772639Z","shell.execute_reply.started":"2023-01-15T08:32:53.764016Z","shell.execute_reply":"2023-01-15T08:32:53.771571Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam , RMSprop \nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n\ndef create_model(verbose=False):\n    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n    \n    x = Conv2D(filters=64, kernel_size=(3,3), padding='same')(input_tensor)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    x = Conv2D(filters=64, kernel_size=(3,3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D(pool_size=(2,2))(x)\n    \n    x = Conv2D(filters=128, kernel_size=(3,3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D(pool_size=(2,2))(x)\n    \n    x = Conv2D(filters=256, kernel_size=3, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters=256, kernel_size=3, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    x = Conv2D(filters=512, kernel_size=3, strides=2, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(rate=0.5)(x)\n    x = Dense(50, activation='relu', name='fc1')(x)\n    x = Dropout(rate=0.2)(x)\n    output = Dense(10, activation='softmax', name='output')(x)\n    \n    model = Model(inputs=input_tensor, outputs=output)\n    if verbose:\n        model.summary()\n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-01-15T08:41:26.058494Z","iopub.execute_input":"2023-01-15T08:41:26.059117Z","iopub.status.idle":"2023-01-15T08:41:26.076681Z","shell.execute_reply.started":"2023-01-15T08:41:26.059076Z","shell.execute_reply":"2023-01-15T08:41:26.075705Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = create_model(verbose=True)\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nrlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\nely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T08:44:55.303793Z","iopub.execute_input":"2023-01-15T08:44:55.304592Z","iopub.status.idle":"2023-01-15T08:44:55.461268Z","shell.execute_reply.started":"2023-01-15T08:44:55.304556Z","shell.execute_reply":"2023-01-15T08:44:55.460261Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 32, 32, 64)        1792      \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 32, 32, 64)        256       \n_________________________________________________________________\nactivation_7 (Activation)    (None, 32, 32, 64)        0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 32, 32, 64)        36928     \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 32, 32, 64)        256       \n_________________________________________________________________\nactivation_8 (Activation)    (None, 32, 32, 64)        0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 16, 16, 128)       73856     \n_________________________________________________________________\nbatch_normalization_9 (Batch (None, 16, 16, 128)       512       \n_________________________________________________________________\nactivation_9 (Activation)    (None, 16, 16, 128)       0         \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 16, 16, 128)       147584    \n_________________________________________________________________\nbatch_normalization_10 (Batc (None, 16, 16, 128)       512       \n_________________________________________________________________\nactivation_10 (Activation)   (None, 16, 16, 128)       0         \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 8, 8, 256)         295168    \n_________________________________________________________________\nbatch_normalization_11 (Batc (None, 8, 8, 256)         1024      \n_________________________________________________________________\nactivation_11 (Activation)   (None, 8, 8, 256)         0         \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 8, 8, 256)         590080    \n_________________________________________________________________\nbatch_normalization_12 (Batc (None, 8, 8, 256)         1024      \n_________________________________________________________________\nactivation_12 (Activation)   (None, 8, 8, 256)         0         \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 4, 4, 512)         1180160   \n_________________________________________________________________\nbatch_normalization_13 (Batc (None, 4, 4, 512)         2048      \n_________________________________________________________________\nactivation_13 (Activation)   (None, 4, 4, 512)         0         \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 512)               0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 512)               0         \n_________________________________________________________________\nfc1 (Dense)                  (None, 50)                25650     \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 50)                0         \n_________________________________________________________________\noutput (Dense)               (None, 10)                510       \n=================================================================\nTotal params: 2,357,360\nTrainable params: 2,354,544\nNon-trainable params: 2,816\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"image_batch, label_batch = next(flow_tr_gen)\nprint(image_batch.shape, label_batch.shape)\nprint(image_batch[0])","metadata":{"execution":{"iopub.status.busy":"2023-01-15T08:45:31.249510Z","iopub.execute_input":"2023-01-15T08:45:31.249926Z","iopub.status.idle":"2023-01-15T08:45:31.264387Z","shell.execute_reply.started":"2023-01-15T08:45:31.249889Z","shell.execute_reply":"2023-01-15T08:45:31.263110Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"(64, 32, 32, 3) (64, 10)\n[[[0.9921569  0.9921569  0.9921569 ]\n  [0.9921569  0.9921569  0.9921569 ]\n  [0.98823535 0.98823535 0.98823535]\n  ...\n  [0.98823535 0.98823535 0.98823535]\n  [0.98823535 0.98823535 0.98823535]\n  [1.         1.         1.        ]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         0.9960785  1.        ]\n  ...\n  [1.         0.9960785  0.9960785 ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         0.9960785  1.        ]\n  ...\n  [1.         0.9960785  0.9960785 ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]]\n\n ...\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         0.9960785 ]\n  ...\n  [1.         1.         0.9960785 ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         0.9960785 ]\n  ...\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]]\n\n [[0.9921569  0.9921569  0.9921569 ]\n  [0.9921569  0.9921569  0.9921569 ]\n  [0.98823535 0.98823535 0.9843138 ]\n  ...\n  [0.98823535 0.98823535 0.98823535]\n  [0.98823535 0.98823535 0.98823535]\n  [1.         1.         1.        ]]]\n","output_type":"stream"}]},{"cell_type":"code","source":"tr_data_len = tr_images.shape[0]\nval_data_len = val_images.shape[0]\n\nhistory = model.fit(flow_tr_gen, epochs=40,\n                   steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)),\n                   validation_data = flow_val_gen,\n                   validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n                   callbacks=[rlr_cb, ely_cb])\n","metadata":{"execution":{"iopub.status.busy":"2023-01-15T08:49:42.463918Z","iopub.execute_input":"2023-01-15T08:49:42.464941Z","iopub.status.idle":"2023-01-15T08:57:39.945604Z","shell.execute_reply.started":"2023-01-15T08:49:42.464867Z","shell.execute_reply":"2023-01-15T08:57:39.944536Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1/40\n665/665 [==============================] - 17s 26ms/step - loss: 1.4275 - accuracy: 0.4787 - val_loss: 1.1679 - val_accuracy: 0.5921\nEpoch 2/40\n665/665 [==============================] - 16s 24ms/step - loss: 0.9951 - accuracy: 0.6518 - val_loss: 1.5988 - val_accuracy: 0.5091\nEpoch 3/40\n665/665 [==============================] - 17s 25ms/step - loss: 0.8150 - accuracy: 0.7205 - val_loss: 1.5954 - val_accuracy: 0.5156\nEpoch 4/40\n665/665 [==============================] - 17s 25ms/step - loss: 0.6950 - accuracy: 0.7662 - val_loss: 0.9948 - val_accuracy: 0.6881\nEpoch 5/40\n665/665 [==============================] - 17s 25ms/step - loss: 0.6027 - accuracy: 0.7981 - val_loss: 0.7364 - val_accuracy: 0.7519\nEpoch 6/40\n665/665 [==============================] - 17s 26ms/step - loss: 0.5300 - accuracy: 0.8252 - val_loss: 1.0599 - val_accuracy: 0.6823\nEpoch 7/40\n665/665 [==============================] - 17s 25ms/step - loss: 0.4758 - accuracy: 0.8410 - val_loss: 0.6943 - val_accuracy: 0.7721\nEpoch 8/40\n665/665 [==============================] - 17s 26ms/step - loss: 0.4425 - accuracy: 0.8527 - val_loss: 0.6444 - val_accuracy: 0.7884\nEpoch 9/40\n665/665 [==============================] - 17s 26ms/step - loss: 0.3862 - accuracy: 0.8709 - val_loss: 0.7363 - val_accuracy: 0.7439\nEpoch 10/40\n665/665 [==============================] - 17s 26ms/step - loss: 0.3564 - accuracy: 0.8804 - val_loss: 0.6041 - val_accuracy: 0.8036\nEpoch 11/40\n665/665 [==============================] - 17s 25ms/step - loss: 0.3207 - accuracy: 0.8933 - val_loss: 0.4739 - val_accuracy: 0.8431\nEpoch 12/40\n665/665 [==============================] - 17s 26ms/step - loss: 0.2882 - accuracy: 0.9045 - val_loss: 0.4709 - val_accuracy: 0.8512\nEpoch 13/40\n665/665 [==============================] - 17s 25ms/step - loss: 0.2670 - accuracy: 0.9102 - val_loss: 0.5185 - val_accuracy: 0.8419\nEpoch 14/40\n665/665 [==============================] - 17s 26ms/step - loss: 0.2382 - accuracy: 0.9208 - val_loss: 0.5025 - val_accuracy: 0.8404\nEpoch 15/40\n665/665 [==============================] - 17s 26ms/step - loss: 0.2155 - accuracy: 0.9271 - val_loss: 0.7528 - val_accuracy: 0.7829\nEpoch 16/40\n665/665 [==============================] - 17s 26ms/step - loss: 0.2017 - accuracy: 0.9327 - val_loss: 0.5285 - val_accuracy: 0.8517\nEpoch 17/40\n665/665 [==============================] - 17s 26ms/step - loss: 0.1817 - accuracy: 0.9407 - val_loss: 0.5089 - val_accuracy: 0.8540\n\nEpoch 00017: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\nEpoch 18/40\n665/665 [==============================] - 17s 25ms/step - loss: 0.0975 - accuracy: 0.9683 - val_loss: 0.3981 - val_accuracy: 0.8941\nEpoch 19/40\n665/665 [==============================] - 17s 26ms/step - loss: 0.0704 - accuracy: 0.9780 - val_loss: 0.4112 - val_accuracy: 0.8939\nEpoch 20/40\n665/665 [==============================] - 17s 25ms/step - loss: 0.0602 - accuracy: 0.9804 - val_loss: 0.4435 - val_accuracy: 0.8948\nEpoch 21/40\n665/665 [==============================] - 17s 26ms/step - loss: 0.0531 - accuracy: 0.9824 - val_loss: 0.4781 - val_accuracy: 0.8856\nEpoch 22/40\n665/665 [==============================] - 17s 25ms/step - loss: 0.0457 - accuracy: 0.9848 - val_loss: 0.4762 - val_accuracy: 0.8888\nEpoch 23/40\n665/665 [==============================] - 17s 26ms/step - loss: 0.0409 - accuracy: 0.9872 - val_loss: 0.4866 - val_accuracy: 0.8928\n\nEpoch 00023: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\nEpoch 24/40\n665/665 [==============================] - 17s 25ms/step - loss: 0.0306 - accuracy: 0.9903 - val_loss: 0.4545 - val_accuracy: 0.8988\nEpoch 25/40\n665/665 [==============================] - 17s 26ms/step - loss: 0.0231 - accuracy: 0.9929 - val_loss: 0.4589 - val_accuracy: 0.8997\nEpoch 26/40\n665/665 [==============================] - 17s 25ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.4578 - val_accuracy: 0.8997\nEpoch 27/40\n665/665 [==============================] - 17s 26ms/step - loss: 0.0226 - accuracy: 0.9928 - val_loss: 0.4646 - val_accuracy: 0.8999\nEpoch 28/40\n665/665 [==============================] - 17s 26ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.4754 - val_accuracy: 0.9000\n\nEpoch 00028: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\nEpoch 00028: early stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"test_generator = ImageDataGenerator(rescale=1/255.0) \nflow_test_gen = test_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\nmodel.evaluate(flow_test_gen)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T09:07:21.900093Z","iopub.execute_input":"2023-01-15T09:07:21.900554Z","iopub.status.idle":"2023-01-15T09:07:23.456338Z","shell.execute_reply.started":"2023-01-15T09:07:21.900511Z","shell.execute_reply":"2023-01-15T09:07:23.455188Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"157/157 [==============================] - 2s 9ms/step - loss: 0.4951 - accuracy: 0.8925\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[0.4951096773147583, 0.8924999833106995]"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_history(history):\n    plt.figure(figsize=(8, 4))\n    plt.yticks(np.arange(0, 1, 0.05))\n    plt.xticks(np.arange(0, 30, 2))\n    plt.plot(history.history['accuary'], label='train')\n    plt.plot(history.history['val_accuracy'], label='valid')\n    plt.legend()\n    \nshow_history(history)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_generator = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=(0.7, 0.9),\n    horizontal_flip=True,\n    vertical_flip=True,\n    rescale=1/255.0\n)\n\nvalid_generator = ImageDataGenerator(rescale=1/255.0)\n\nflow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\nflow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n\nmodel = create_model()\nmodel.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nrlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\nely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n\ntr_data_len = tr_images.shape[0]\nval_data_len = val_images.shape[0]\n\nhistory = model.fit(flow_tr_gen, epochs=40, \n                    steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)),\n                    validation_data=flow_val_gen, \n                    validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n                    callbacks=[rlr_cb, ely_cb], verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_generator = ImageDataGenerator(rescale=1/255.0) \nflow_test_gen = test_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\nmodel.evaluate(flow_test_gen)","metadata":{},"execution_count":null,"outputs":[]}]}